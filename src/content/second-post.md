---
title: Second
description: Second post.
date: '2023-4-16'
categories:
  - sveltekit
  - svelte
published: true
---

<script>
  import Counter from './counter.svelte'
</script>


## Svelte

Media inside the **static** folder is served from `/`.

> Banana

![Svelte](../../favicon.png)

<Counter />

### Classification

Adversarial attacks on classifiers have attracted more attention in the research community in the past, many in the image domain. LLMs can be used for classification too. Given an input $x$ and a classifier $f(.)$, we would like to find an adversarial version of the input, denoted as $x_{\text{adv}}$ with imperceptible difference from $x$, such that $f(x) \neq f(x_{\text{adv}})$.

$$
x_i \sim P_{\theta_i} = \text{Categorical}(\pi_i) = \text{Categorical}(\text{Softmax}(\theta_i))
$$